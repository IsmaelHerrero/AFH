<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Manual Técnico: Despliegue de Agente IA con OpenCode y LM Studio</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #2c3e50;
            max-width: 950px;
            margin: 0 auto;
            padding: 40px;
            background-color: #f8f9fa;
        }
        header {
            text-align: center;
            margin-bottom: 40px;
            border-bottom: 3px solid #3498db;
            padding-bottom: 20px;
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 10px;
        }
        .subtitle {
            color: #7f8c8d;
            font-size: 1.2em;
            font-weight: 300;
        }
        section {
            background: #ffffff;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.05);
            transition: transform 0.2s;
        }
        section:hover {
            transform: translateY(-2px);
        }
        h2 {
            color: #2980b9;
            border-left: 5px solid #3498db;
            padding-left: 15px;
            margin-top: 0;
        }
        h3 {
            color: #34495e;
            margin-top: 20px;
        }
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        .highlight {
            background-color: #e8f4f8;
            padding: 15px;
            border-radius: 6px;
            border-left: 4px solid #1abc9c;
            margin: 15px 0;
        }
        .hardware-note {
            background-color: #fff3cd;
            border-left: 4px solid #f1c40f;
            padding: 15px;
            color: #856404;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        code {
            background-color: #f1f2f6;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Consolas', 'Monaco', monospace;
            color: #c0392b;
            font-size: 0.95em;
        }
        ul {
            padding-left: 20px;
        }
        li {
            margin-bottom: 10px;
        }
    </style>
</head>
<body>

    <header>
        <h1>Manual de Despliegue de Agente IA Local</h1>
        <p class="subtitle">Ampliación de Fundamentos del Hardware e Integración con OpenCode</p>
    </header>

    <section>
        <h2>1. Selección del Modelo y Entorno de Hardware</h2>
        <p>Para la realización de esta tarea, se ha seleccionado el modelo <strong>Qwen 2.5 Coder 3B Instruct</strong>. Esta elección no es arbitraria, sino que responde a criterios técnicos específicos relacionados con el hardware disponible:</p>
        
        <div class="hardware-note">
            <strong>Justificación del Hardware:</strong>
            <p>Se ha optado por un modelo "ligero" (3 billones de parámetros) pensando en entornos físicos con limitaciones, como tarjetas gráficas <strong>NVIDIA 3050 Ti con 4GB de VRAM</strong>. Un modelo más grande excedería la memoria de video, obligando al sistema a usar la memoria RAM convencional, lo cual es aproximadamente <strong>20 veces más lento</strong>.</p>
        </div>

        <p>El objetivo es mantener todo el proceso dentro de la GPU para garantizar fluidez en la generación de código.</p>
        <img src="im/image5.png" alt="Selección del modelo Qwen 3B Coder en LM Studio">
    </section>

    <section>
        <h2>2. Configuración Avanzada en LM Studio</h2>
        <p>Para maximizar el rendimiento y evitar errores durante conversaciones largas, se han aplicado las siguientes configuraciones críticas en el servidor local:</p>
        
        <ul>
            <li><strong>Context Length (Longitud de Contexto):</strong> Ajustado a <code>12288 tokens</code>. Aunque el modelo soporta más, limitarlo ayuda a mantener el consumo de VRAM bajo control y evita desbordamientos de memoria.</li>
            <li><strong>GPU Offload:</strong> Configurado al máximo para asegurar que las capas del modelo se procesen en la tarjeta gráfica.</li>
            <li><strong>Server Port:</strong> Se establece el puerto <code>1234</code> para la escucha de peticiones.</li>
        </ul>

        <img src="im/image4.png" alt="Configuración de contexto y descarga a GPU">
        
        <div class="highlight">
            <p><strong>Configuración de Red:</strong> Es vital desactivar la autenticación y asegurar el puerto correcto para facilitar la conexión sin barreras desde el entorno de desarrollo local.</p>
        </div>
        <img src="im/image1.png" alt="Puerto del servidor 1234 sin autenticación">
    </section>

    <section>
        <h2>3. Integración con OpenCode (El Agente)</h2>
        <p>La integración se realiza mediante un archivo de configuración JSON llamado <code>opencode.json</code>. Este paso es fundamental porque actúa como un <strong>intermediario o "trick"</strong>:</p>
        <p>OpenCode está diseñado por defecto para consultar a la API de OpenAI en la nube. Mediante este archivo, "engañamos" al agente redirigiendo sus peticiones a <code>localhost</code> (nuestra máquina). LM Studio emula la estructura de respuestas de OpenAI, permitiendo que el agente funcione offline.</p>
        
        <h3>Configuración del archivo opencode.json:</h3>
        <ul>
            <li><strong>BaseURL:</strong> <code>http://localhost:1234/v1</code> (Apunta a nuestro LM Studio).</li>
            <li><strong>Provider:</strong> Se define como compatible con OpenAI.</li>
            <li><strong>Model ID:</strong> Se especifica el nombre interno del modelo cargado localmente.</li>
        </ul>
        <img src="im/image7.png" alt="Código JSON de configuración en OpenCode">
    </section>

    <section>
        <h2>4. Validación y Pruebas Interactivas</h2>
        <p>Una vez conectado, el modelo actúa como un <strong>Agente Especializado</strong>. En este caso, se le ha asignado un rol de asistencia para el "Área Financiera y Contabilidad (AFH)", aunque sus capacidades de código son generales.</p>
        
        <h3>Prueba de Identidad:</h3>
        <p>Verificamos que el agente está activo y entiende su contexto mediante un chat directo:</p>
        <img src="im/image3.png" alt="Chat de verificación de estado del servidor local">

        <h3>Prueba de Generación de Código:</h3>
        <p>Se solicitó al agente crear una estructura web HTML sobre animales. El modelo <strong>Qwen Coder</strong> demuestra su capacidad generando sintaxis limpia y funcional instantáneamente.</p>
        <img src="im/image6.png" alt="Generación de código HTML por el agente">
    </section>

    <section>
        <h2>5. Monitorización y Prueba de Ejecución</h2>
        <p>Para confirmar que la tarea se está ejecutando realmente en el hardware local y no en la nube, monitoreamos el historial de la GPU.</p>
        <p>En la siguiente captura (tomada en un entorno Apple Silicon M4 utilizado para la demostración en clase), se observan los picos de actividad en la GPU integrada correspondientes a los momentos de inferencia (generación de texto) del agente.</p>
        <img src="im/image2.png" alt="Monitor de actividad de GPU Apple M4 mostrando carga de trabajo">
    </section>

</body>
</html>
