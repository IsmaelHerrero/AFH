<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Comparativa Rendimiento IAs - Windows vs Mac</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            min-height: 100vh;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: rgba(255,255,255,0.97);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.15);
        }

        h1 {
            text-align: center;
            color: #4a5568;
            margin-bottom: 10px;
            font-size: 2.5em;
        }

        h2 {
            color: #2d3748;
            margin-top: 40px;
            margin-bottom: 10px;
            font-size: 1.8em;
        }

        h3 {
            color: #2d3748;
            margin-top: 25px;
            margin-bottom: 8px;
            font-size: 1.3em;
        }

        .subtitle {
            text-align: center;
            color: #718096;
            margin-bottom: 30px;
            font-size: 1.1em;
        }

        .intro-text {
            max-width: 1200px;
            margin: 0 auto 25px auto;
            color: #2d3748;
            font-size: 0.98em;
            line-height: 1.6;
        }

        .charts-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 20px;
        }

        .chart-container {
            background: #ffffff;
            padding: 20px 22px 16px 22px;
            border-radius: 15px;
            box-shadow: 0 10px 25px rgba(0,0,0,0.08);
            border: 1px solid #e2e8f0;
        }

        .chart-title {
            text-align: center;
            font-size: 1.2em;
            color: #2d3748;
            margin-bottom: 14px;
            font-weight: 600;
        }

        .chart-description-block {
            margin-top: 18px;
            padding: 14px 16px;
            border-radius: 12px;
            background: #f8fafc;
            border: 1px solid #e2e8f0;
            font-size: 0.93em;
            color: #4a5568;
            line-height: 1.5;
        }

        .chart-description-block p {
            margin: 6px 0;
        }

        .accuracy-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-top: 20px;
        }

        .tokens-section,
        .scores-section,
        .tables-section {
            margin-top: 35px;
        }

        .tokens-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-top: 10px;
        }

        .simple-card {
            background: #ffffff;
            padding: 20px;
            border-radius: 15px;
            box-shadow: 0 8px 20px rgba(0,0,0,0.06);
            border: 1px solid #e2e8f0;
        }

        .simple-card-title {
            font-size: 1.15em;
            font-weight: 600;
            color: #2d3748;
            margin-bottom: 10px;
            text-align: center;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.92em;
        }

        table thead {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        table th {
            padding: 10px 12px;
            text-align: left;
            font-weight: 600;
        }

        table td {
            padding: 9px 12px;
            border-bottom: 1px solid #e2e8f0;
        }

        table tbody tr:nth-child(even) {
            background-color: #f9fafb;
        }

        table tbody tr:hover {
            background-color: #f1f5f9;
        }

        .score {
            font-weight: 600;
            color: #2d3748;
        }

        .cost-pill {
            display: inline-block;
            padding: 4px 10px;
            border-radius: 999px;
            font-size: 0.8em;
            font-weight: 600;
        }

        .cost-high {
            background-color: #f8d7da;
            color: #721c24;
        }

        .cost-mid {
            background-color: #fff3cd;
            color: #856404;
        }

        .cost-low {
            background-color: #d1ecf1;
            color: #0c5460;
        }

        .cost-efficient {
            background-color: #d4edda;
            color: #155724;
        }

        .note-text {
            margin-top: 12px;
            font-size: 0.9em;
            color: #4a5568;
            line-height: 1.6;
        }

        .riddles-block {
            margin-top: 25px;
            padding: 18px 20px;
            border-radius: 15px;
            background: #edf2ff;
            border: 1px solid #c3dafe;
            font-size: 0.92em;
            line-height: 1.6;
            color: #2a4365;
        }

        @media (max-width: 1200px) {
            .charts-grid,
            .accuracy-grid,
            .tokens-grid {
                grid-template-columns: 1fr;
            }
        }

        @media (max-width: 768px) {
            .container {
                padding: 18px;
            }
        }
    </style>
</head>
<body>

    <div class="intro-text">
        <p>Este trabajo se enfoca en comparar 4 modelos de IA en local, tanto en entorno Windows como en entorno Mac, usando LM Studio como framework para descargar, modificar y probar las IAs. Cada equipo cuenta con su potencia relativa: el Mac posee 16 GB de RAM unificada en el procesador, mientras que el equipo con Windows dispone de una tarjeta gráfica dedicada, una 5060 Ti de 16 GB de VRAM GDDR7.</p>
        <p>La batería de preguntas seleccionada para probar los modelos de inteligencia artificial se basa en 10 preguntas cortas, combinando acertijos lingüísticos y lógica simple.</p>
    </div>

    <div class="riddles-block">
        <strong>Batería de acertijos utilizada en las pruebas:</strong><br><br>
        1. Acertijo: Tiene agujas pero no cose. Respuesta: El reloj.<br>
        2. Acertijo: Vuela sin alas y hace sombra. Respuesta: Las nubes.<br>
        3. Acertijo: Es tuyo, pero otros lo usan más que tú. Respuesta: Tu nombre.<br>
        4. Acertijo: ¿Qué cosa se moja mientras seca? Respuesta: La toalla.<br>
        5. Acertijo: Tiene dientes pero no muerde. Respuesta: El peine.<br>
        6. Acertijo: ¿Qué sube pero nunca baja? Respuesta: La edad.<br>
        7. Acertijo: Blanco por dentro, verde por fuera. Si quieres que te lo diga, espera. Respuesta: La pera.<br>
        8. Acertijo: Utensilio dentado para cortar madera. Respuesta: Sierra / motosierra.<br>
        9. Acertijo: Cuanto más grande es, menos se ve. Respuesta: La oscuridad.<br>
        10. Acertijo: Tiene patas, pero no camina. Respuesta: La mesa (o la silla).
    </div>

    <div class="container">
        <h1>Comparativa Rendimiento IAs</h1>
        <p class="subtitle">Tokens/segundo, Tokens Totales, Tiempo Primer Token y Tiempo Total - Batería de 10 preguntas</p>

        <!-- SECCIÓN 1: Rendimiento completo Windows / Mac -->
        <h2>Rendimiento completo por sistema</h2>
        <div class="charts-grid">
            <div class="chart-container">
                <div class="chart-title">Windows - Rendimiento Completo</div>
                <canvas id="windowsPerformance"></canvas>
            </div>

            <div class="chart-container">
                <div class="chart-title">Mac - Rendimiento Completo</div>
                <canvas id="macPerformance"></canvas>
            </div>
        </div>

        <div class="chart-description-block">
            <h3>Descripción del rendimiento Windows/Mac</h3>
            <p>Estas gráficas muestran las discrepancias cuantitativas de rendimiento de los 4 modelos de IA entre Windows y MAC (tokens/segundo, tokens totales, TTFT y tiempo total para dar la respuesta) las gráficas son interactivas y si se pincha sobre el nombre en la parte superior de las gráficas, se puede esconder esa barra/parámetro para hacer el resto se vean con mayor claridad. 
               Respecto al anásis técnico, puedo decir que en Windows, Qwen3 y Qwen3 Thinking alcanzan más de 100 tokens/segundo, mientras que GPT-OSS es más lento pero más estable. El tiempo total refleja que Qwen3 Thinking tarda mucho más en responder la batería completa.</p>
            <p>En Mac, todos los modelos tienen menos tokens/segundo, especialmente Qwen3 y Qwen3 Thinking, que caen drásticamente. GPT-OSS mantiene un rendimiento más estable, pero el TTFT (tiempo hasta el primer token) se dispara en todos los modelos, lo que indica que el hardware sin GPU dedicada penaliza mucho la inferencia local.</p>
            <p>En este trabajo se probaron 4 IAs diferentes (Open GPT OSS, Qwen3 v3, Qwen3 Thinking y Granite H4 Tiny). Los tokens por segundo suelen ser elevados en modelos pequeños con pocos billones de parámetros especialmente en Windows, con modelos como Qwen3 v3, Qwen3 Thinking que triplican los tokens por segundo respecto a la prueba en MAC y Granite que los duplica respecto su contraparte en MAC. Casi todas las IA tienen el mismo TTFT de pocos segundos o milisegundos, pero en tiempo de respuesta Qwen3 v3 y Granite rindieron por debajo de 10 segundos, mientras que GPT-OSS tardó casi 1 minuto y Qwen3 Thinking más de 2 minutos, llegando a alucinar en algunas respuestas.</p>
            <p>Se observa que en sistemas Mac, sin tarjetas gráficas con núcleos CUDA, el número de tokens por segundo es mucho menor y todas las IAs rinden peor, especialmente los modelos pequeños, que reducen sus tokens/segundo a menos de la mitad que en Windows. GPT-OSS mantiene un rendimiento similar en tokens/segundo, pero el TTFT se dispara, llegando a 10 segundos en algunos casos.</p>
        </div>

        <!-- SECCIÓN 2: Aciertos Windows / Mac -->
        <h2>Respuestas correctas por modelo</h2>
        <div class="accuracy-grid">
            <div class="chart-container">
                <div class="chart-title">Windows - Respuestas Correctas</div>
                <canvas id="windowsAccuracy"></canvas>
            </div>

            <div class="chart-container">
                <div class="chart-title">Mac - Respuestas Correctas</div>
                <canvas id="macAccuracy"></canvas>
            </div>
        </div>

        <div class="chart-description-block">
            <h3>Descripción de aciertos Windows/Mac</h3>
            <p>En Windows, GPT-OSS logra 9 de 10 aciertos, mientras que Qwen3, Granite y Qwen3 Thinking obtienen entre 4 y 5 aciertos. Esto indica que, aunque Qwen3 y Qwen3 Thinking son rápidos, su precisión en acertijos lógicos es inferior a la de GPT-OSS.</p>
            <p>En Mac, GPT-OSS mantiene los 9 aciertos, pero Qwen3 Thinking cae a 0 aciertos, lo que sugiere que en entornos con menos potencia este modelo tiende a alucinar y fallar incluso en preguntas sencillas. Qwen3 y Granite se mantienen en el rango de 4–5 aciertos.</p>
        </div>

        <!-- SECCIÓN 3: Tokens totales Windows / Mac -->
        <div class="tokens-section">
            <h2>Tokens totales por modelo y sistema</h2>

            <div class="tokens-grid">
                <div class="simple-card">
                    <div class="simple-card-title">Tokens totales en Windows</div>
                    <table>
                        <thead>
                            <tr>
                                <th>Modelo (Windows)</th>
                                <th>Tokens totales</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>GPT-OSS 20B</td>
                                <td>1539 tokens</td>
                            </tr>
                            <tr>
                                <td>Qwen 3 VL 4B</td>
                                <td>910 tokens</td>
                            </tr>
                            <tr>
                                <td>Granite 4.0 Tiny</td>
                                <td>79 tokens</td>
                            </tr>
                            <tr>
                                <td>Qwen 3 Thinking</td>
                                <td>14400 tokens</td>
                            </tr>
                        </tbody>
                    </table>
                    <p class="note-text"><strong>Qwen 3 Thinking</strong> en Windows es con diferencia el modelo que más tokens usó para proporcionar una respuesta, mientras que <strong>Granite</strong> se mantiene en el extremo de máxima concisión.</p>
                </div>

                <div class="simple-card">
                    <div class="simple-card-title">Tokens totales en Mac</div>
                    <table>
                        <thead>
                            <tr>
                                <th>Modelo (Mac)</th>
                                <th>Tokens totales</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>GPT-OSS 20B</td>
                                <td>600 tokens</td>
                            </tr>
                            <tr>
                                <td>Qwen 3 VL 4B</td>
                                <td>4344 tokens</td>
                            </tr>
                            <tr>
                                <td>Granite 4.0 Tiny</td>
                                <td>904 tokens</td>
                            </tr>
                            <tr>
                                <td>Qwen 3 Thinking</td>
                                <td>3405 tokens</td>
                            </tr>
                        </tbody>
                    </table>
                    <p class="note-text">En Mac, Qwen 3 VL y Qwen 3 Thinking tienden a producir respuestas mucho más largas que GPT-OSS y Granite ante la misma batería de preguntas, mostrando que los modelos Qwen tienden a dar respuestas mas largas que otros modelos, independientemente de la sencillez de las preguntas.</p>
                </div>
            </div>

            <div class="chart-description-block">
                <h3>Descripción sobre longitud de respuestas</h3>
                <p>En Windows, Qwen3 Thinking genera una cantidad de tokens muy superior al resto, lo que se traduce en respuestas extremadamente largas y en ocasiones con alucinaciones. Granite, por el contrario, concentra la información en muy pocos tokens, ofreciendo respuestas concisas y directas.</p>
                <p>En Mac, Qwen3 VL y Qwen3 Thinking incrementan todavía más la longitud de sus respuestas respecto a GPT-OSS y Granite, lo que indica que estos modelos tienden a extenderse al razonar, sobre todo en hardware menos potente. GPT-OSS y Granite son más sucintos, con respuestas más cortas y fáciles de leer.</p>
                <p>También se detecta que, en Windows, las IAs suelen responder con menos tokens que en Mac, salvo en el caso de Qwen3 Thinking, que puede llegar a generar hasta 14400 tokens, muchos de ellos ocultos en el razonamiento previo a la respuesta.</p>
            </div>
        </div>

        <!-- SECCIÓN 4: Distribución de puntuaciones -->
        <div class="scores-section">
            <h2>Puntuación final asignada a cada modelo</h2>

            <div class="charts-grid">
                <div class="chart-container">
                    <div class="chart-title">Distribución de Puntuaciones - Modelos</div>
                    <canvas id="scoreDistribution"></canvas>
                </div>
            </div>

            <div class="chart-description-block">
                <h3>Descripción de la puntuación final</h3>
                <p>Esta gráfica muestra la puntuación final asignada a cada modelo: GPT-OSS 9/10, Granite 7/10, Qwen3 VL 6/10 y Qwen3 Thinking 5/10. La puntuación refleja un balance entre rendimiento, precisión y utilidad general.</p>
                <p>GPT-OSS destaca por su fiabilidad y alto número de aciertos, mientras que Qwen3 Thinking pierde puntos por su tendencia a alucinar y por el exceso de tokens generados. Granite y Qwen3 VL quedan en posiciones intermedias, equilibrando velocidad, claridad y coste de recursos.</p>
            </div>
        </div>

        <!-- SECCIÓN 5: Tabla cualitativa de virtudes / fallos -->
        <div class="tables-section">
            <h2>Evaluación cualitativa de los modelos</h2>

            <div class="simple-card">
                <div class="simple-card-title">Comparativa detallada de modelos</div>
                <table>
                    <thead>
                        <tr>
                            <th>Modelo</th>
                            <th>Puntuación</th>
                            <th>Virtudes y fallos detectados</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>GPT-OSS 20B</strong></td>
                            <td class="score">9/10</td>
                            <td>Virtudes: Cumplidor. Resuelve correctamente la mayoría de preguntas o problemas de lógica secuencial (quién vive en qué casa) y mantiene la coherencia. Fallos: Es fiable pero le falta un poco de creatividad.</td>
                        </tr>
                        <tr>
                            <td><strong>Granite 4.0 Tiny</strong></td>
                            <td class="score">7/10</td>
                            <td>Virtudes: Concisión extrema. Si solo se busca un dato puntual sin texto alrededor, es rápido. Fallos: Carece de capacidad conversacional; sus respuestas son listas de palabras o monosílabos sin conectar frases.</td>
                        </tr>
                        <tr>
                            <td><strong>Qwen 3 VL 4B</strong></td>
                            <td class="score">6/10</td>
                            <td>Virtudes: No solo acierta, sino que justifica sus respuestas con matices, explicando el contexto (por ejemplo, entiende el doble sentido en acertijos de lenguaje). Fallos: Es poco fiable; requirió varios intentos para entender bien algunas baterías de preguntas.</td>
                        </tr>
                        <tr>
                            <td><strong>Qwen 3 Thinking</strong></td>
                            <td class="score">5/10</td>
                            <td>Virtudes: Muestra su cadena de pensamiento (“Thinking Process”), útil para ver cómo intenta deducir. Fallos: Sufre de sobreanálisis y puede acabar alucinando respuestas incorrectas en acertijos básicos.</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <!-- SECCIÓN 6: Coste computacional / resumen técnico -->
            <h2>Coste computacional y perfil técnico</h2>

            <div class="simple-card">
                <div class="simple-card-title">Coste computacional y eficiencia</div>
                <table>
                    <thead>
                        <tr>
                            <th>Modelo</th>
                            <th>Almacenamiento</th>
                            <th>Latencia</th>
                            <th>Velocidad (T/s)</th>
                            <th>Veredicto final</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>GPT-OSS 20B</td>
                            <td>12.10 GB</td>
                            <td>0.49 s</td>
                            <td>35.04 T/s</td>
                            <td>
                                <span class="cost-pill cost-high">Alto coste</span>
                                <div style="font-size:0.8em; color:#555; margin-top:4px;">Pesado y lento</div>
                            </td>
                        </tr>
                        <tr>
                            <td>Qwen 3 VL 4B</td>
                            <td>3.11 GB</td>
                            <td>0.61 s</td>
                            <td>39.14 T/s</td>
                            <td>
                                <span class="cost-pill cost-mid">Medio</span>
                                <div style="font-size:0.8em; color:#555; margin-top:4px;">Latencia alta</div>
                            </td>
                        </tr>
                        <tr>
                            <td>Granite 4.0 Tiny</td>
                            <td>4.23 GB</td>
                            <td>0.16 s</td>
                            <td>81.75 T/s</td>
                            <td>
                                <span class="cost-pill cost-low">Bajo</span>
                                <div style="font-size:0.8em; color:#555; margin-top:4px;">Respuestas concisas</div>
                            </td>
                        </tr>
                        <tr>
                            <td>Qwen 3 Thinking</td>
                            <td>2.28 GB</td>
                            <td>0.19 s</td>
                            <td>79.41 T/s</td>
                            <td>
                                <span class="cost-pill cost-efficient">Eficiente</span>
                                <div style="font-size:0.8em; color:#555; margin-top:4px;">Top en tok/sec</div>
                            </td>
                        </tr>
                    </tbody>
                </table>

                <div class="note-text">
                    <p>GPT-OSS 20B es el modelo más pesado en almacenamiento y uno de los más lentos en tokens/segundo, pero ofrece una alta precisión y estabilidad en las respuestas. Su coste computacional es elevado, por lo que resulta más adecuado para equipos con buena GPU.</p>
                    <p>Qwen 3 VL 4B y Qwen 3 Thinking son mucho más ligeros y alcanzan velocidades muy altas en tokens/segundo, lo que los hace atractivos para entornos con recursos limitados. Granite 4.0 Tiny combina buena velocidad con respuestas muy concisas, siendo una opción equilibrada cuando se busca rapidez y claridad sin un consumo excesivo de recursos.</p>
                </div>
            </div>

            <div class="note-text">
                <p>Se observa por la diferencia de tokens por segundo que en sistemas Mac, carentes de tarjetas gráficas dedicadas con núcleos CUDA, el número de tokens por segundo es mucho menor y todas las IAs rinden menos, especialmente las de pocos parámetros como Qwen3, Granite y Qwen3 Thinking, que reducen sus tokens por segundo a menos de la mitad que en Windows. Aunque GPT-OSS rinde a casi los mismos tokens por segundo, el tiempo hasta el primer token (TTFT) se dispara, llegando a 10 segundos en algunos casos.</p>
                <p>De esta comparativa se extrae que las tarjetas gráficas NVIDIA y su arquitectura de núcleos CUDA hacen rendir mucho más y aceleran los modelos de IA locales, especialmente los modelos pequeños, mientras que en los grandes disminuye el tiempo hasta el primer token. Además, en Windows las IAs suelen responder con menos tokens que en Mac, salvo en el caso de Qwen3 Thinking, que llegó a generar 14400 tokens, muchos de ellos ocultos en el razonamiento previo a la respuesta.</p>
            </div>
        </div>

    </div>

    <script>
        // Datos de rendimiento Windows
        const dataWindowsPerf = {
            labels: ['GPT-OSS', 'Qwen3 VL', 'Granite', 'Qwen3 Thinking'],
            datasets: [
                {
                    label: 'Tokens/segundo',
                    data: [36.19, 109.11, 72.71, 101.20],
                    backgroundColor: 'rgba(54, 162, 235, 0.8)',
                    borderColor: 'rgba(54, 162, 235, 1)',
                    borderWidth: 1
                },
                {
                    label: 'Tokens Totales (x100)',
                    data: [15.39, 9.10, 0.79, 144.00],
                    backgroundColor: 'rgba(255, 206, 86, 0.8)',
                    borderColor: 'rgba(255, 206, 86, 1)',
                    borderWidth: 1
                },
                {
                    label: 'TTFT (seg x10)',
                    data: [5.2, 1.4, 1.6, 2.2],
                    backgroundColor: 'rgba(75, 192, 192, 0.8)',
                    borderColor: 'rgba(75, 192, 192, 1)',
                    borderWidth: 1
                },
                {
                    label: 'Tiempo Total (seg)',
                    data: [43.08, 8.62, 1.25, 142.51],
                    backgroundColor: 'rgba(255, 99, 132, 0.8)',
                    borderColor: 'rgba(255, 99, 132, 1)',
                    borderWidth: 1
                }
            ]
        };

        // Datos de rendimiento Mac
        const dataMacPerf = {
            labels: ['GPT-OSS', 'Qwen3 VL', 'Granite', 'Qwen3 Thinking'],
            datasets: [
                {
                    label: 'Tokens/segundo',
                    data: [34.15, 34.76, 39.14, 34.32],
                    backgroundColor: 'rgba(54, 162, 235, 0.8)',
                    borderColor: 'rgba(54, 162, 235, 1)',
                    borderWidth: 1
                },
                {
                    label: 'Tokens Totales (x100)',
                    data: [6.00, 43.44, 9.04, 34.05],
                    backgroundColor: 'rgba(255, 206, 86, 0.8)',
                    borderColor: 'rgba(255, 206, 86, 1)',
                    borderWidth: 1
                },
                {
                    label: 'TTFT (seg x10)',
                    data: [106.4, 7.2, 6.1, 6.9],
                    backgroundColor: 'rgba(75, 192, 192, 0.8)',
                    borderColor: 'rgba(75, 192, 192, 1)',
                    borderWidth: 1
                },
                {
                    label: 'Tiempo Total (seg)',
                    data: [27.56, 125.69, 27.08, 99.9],
                    backgroundColor: 'rgba(255, 99, 132, 0.8)',
                    borderColor: 'rgba(255, 99, 132, 1)',
                    borderWidth: 1
                }
            ]
        };

        // Datos de aciertos Windows
        const dataAccuracyWindows = {
            labels: ['GPT-OSS', 'Qwen3 VL', 'Granite', 'Qwen3 Thinking'],
            datasets: [{
                label: 'Respuestas Correctas (de 10)',
                data: [9, 4, 5, 4],
                backgroundColor: [
                    'rgba(34, 197, 94, 0.8)',
                    'rgba(249, 115, 22, 0.8)',
                    'rgba(59, 130, 246, 0.8)',
                    'rgba(168, 85, 247, 0.8)'
                ],
                borderColor: [
                    'rgba(34, 197, 94, 1)',
                    'rgba(249, 115, 22, 1)',
                    'rgba(59, 130, 246, 1)',
                    'rgba(168, 85, 247, 1)'
                ],
                borderWidth: 1
            }]
        };

        // Datos de aciertos Mac
        const dataAccuracyMac = {
            labels: ['GPT-OSS', 'Qwen3 VL', 'Granite', 'Qwen3 Thinking'],
            datasets: [{
                label: 'Respuestas Correctas (de 10)',
                data: [9, 4, 5, 0],
                backgroundColor: [
                    'rgba(34, 197, 94, 0.8)',
                    'rgba(249, 115, 22, 0.8)',
                    'rgba(59, 130, 246, 0.8)',
                    'rgba(168, 85, 247, 0.8)'
                ],
                borderColor: [
                    'rgba(34, 197, 94, 1)',
                    'rgba(249, 115, 22, 1)',
                    'rgba(59, 130, 246, 1)',
                    'rgba(168, 85, 247, 1)'
                ],
                borderWidth: 1
            }]
        };

        // Datos de puntuación final
        const dataScoreDistribution = {
            labels: [
                'GPT-OSS 20B (9/10)',
                'Granite 4.0 Tiny (7/10)',
                'Qwen 3 VL 4B (6/10)',
                'Qwen 3 Thinking (5/10)'
            ],
            datasets: [{
                label: 'Puntuaciones',
                data: [9, 7, 6, 5],
                backgroundColor: [
                    'rgba(34, 197, 94, 0.8)',
                    'rgba(59, 130, 246, 0.8)',
                    'rgba(249, 115, 22, 0.8)',
                    'rgba(239, 68, 68, 0.8)'
                ],
                borderColor: [
                    'rgba(34, 197, 94, 1)',
                    'rgba(59, 130, 246, 1)',
                    'rgba(249, 115, 22, 1)',
                    'rgba(239, 68, 68, 1)'
                ],
                borderWidth: 1
            }]
        };

        const commonOptions = {
            responsive: true,
            plugins: {
                legend: {
                    position: 'top'
                }
            },
            scales: {
                y: {
                    beginAtZero: true,
                    grid: {
                        color: 'rgba(0,0,0,0.05)'
                    }
                },
                x: {
                    grid: {
                        display: false
                    }
                }
            }
        };

        // Crear gráficos
        const ctxWinPerf = document.getElementById('windowsPerformance').getContext('2d');
        new Chart(ctxWinPerf, {
            type: 'bar',
            data: dataWindowsPerf,
            options: commonOptions
        });

        const ctxMacPerf = document.getElementById('macPerformance').getContext('2d');
        new Chart(ctxMacPerf, {
            type: 'bar',
            data: dataMacPerf,
            options: commonOptions
        });

        const ctxWinAcc = document.getElementById('windowsAccuracy').getContext('2d');
        new Chart(ctxWinAcc, {
            type: 'bar',
            data: dataAccuracyWindows,
            options: commonOptions
        });

        const ctxMacAcc = document.getElementById('macAccuracy').getContext('2d');
        new Chart(ctxMacAcc, {
            type: 'bar',
            data: dataAccuracyMac,
            options: commonOptions
        });

        const ctxScore = document.getElementById('scoreDistribution').getContext('2d');
        new Chart(ctxScore, {
            type: 'bar',
            data: dataScoreDistribution,
            options: commonOptions
        });
    </script>
</body>
</html>
